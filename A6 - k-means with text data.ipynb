{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due: Wednesday, 16th May, at 11:59 pm on Canvas\n",
    "\n",
    "In this assignment you will\n",
    "* Cluster Wikipedia documents using k-means\n",
    "* Explore the role of random initialization on the quality of the clustering\n",
    "* Explore how results differ after changing the number of clusters\n",
    "* Evaluate clustering, both quantitatively and qualitatively\n",
    "\n",
    "When properly executed, clustering uncovers valuable insights from a set of unlabeled documents.\n",
    "\n",
    "Copyright Â©2018 Emily Fox.  All rights reserved.  Permission is hereby granted to students registered for University of Washington CSE/STAT 416 for use solely during Spring Quarter 2018 for purposes of the course.  No other use, copying, distribution, or modification is permitted without prior written consent. Copyrights for third-party components of this work must be honored.  Instructors interested in reusing these course materials should contact the author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with text data, we must first convert the documents into numerical features. As in the first assignment, let's extract TF-IDF features for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki, _ = tc.SFrame('/data/people_wiki.gl/').random_split(0.1, seed=0) # Using 10% of the data, due to limited resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">URI</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Grant_Nelson&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Grant Nelson</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">grant nelson born 27<br>april 1971 in london  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Cathy_Caruth&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Cathy Caruth</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">cathy caruth born 1955 is<br>frank h t rhodes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Ian_Mitchell_(aut ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Ian Mitchell (author)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">ian mitchell is a<br>scottish author who grew ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Ted_Hill_(mathema ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Ted Hill (mathematician)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">theodore preston hill<br>born december 28 1943 is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Steven_Weil&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Steven Weil</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">steven weil is an<br>american rabbi who grew ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Rob_Sheffield&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Rob Sheffield</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">rob sheffield born<br>february 2 1966 is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Michel_Che&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Michel Che</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">professor michel che born<br>in lyon france completed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Vincent_Fang_(lyr ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Vincent Fang (lyricist)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">for a hong kong<br>entrepreneur please r ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Susan_Christie&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Susan Christie</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">susan christie is an<br>american singersongwr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Quintin_E._Primo_ ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Quintin E. Primo III</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">quintin e primo iii born<br>march 14 1955 is the ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[? rows x 3 columns]<br/>Note: Only the head of the SFrame is printed. This SFrame is lazily evaluated.<br/>You can use sf.materialize() to force materialization.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tURI\tstr\n",
       "\tname\tstr\n",
       "\ttext\tstr\n",
       "\n",
       "Rows: Unknown\n",
       "\n",
       "Data:\n",
       "+-------------------------------+--------------------------+\n",
       "|              URI              |           name           |\n",
       "+-------------------------------+--------------------------+\n",
       "| <http://dbpedia.org/resour... |       Grant Nelson       |\n",
       "| <http://dbpedia.org/resour... |       Cathy Caruth       |\n",
       "| <http://dbpedia.org/resour... |  Ian Mitchell (author)   |\n",
       "| <http://dbpedia.org/resour... | Ted Hill (mathematician) |\n",
       "| <http://dbpedia.org/resour... |       Steven Weil        |\n",
       "| <http://dbpedia.org/resour... |      Rob Sheffield       |\n",
       "| <http://dbpedia.org/resour... |        Michel Che        |\n",
       "| <http://dbpedia.org/resour... | Vincent Fang (lyricist)  |\n",
       "| <http://dbpedia.org/resour... |      Susan Christie      |\n",
       "| <http://dbpedia.org/resour... |   Quintin E. Primo III   |\n",
       "+-------------------------------+--------------------------+\n",
       "+-------------------------------+\n",
       "|              text             |\n",
       "+-------------------------------+\n",
       "| grant nelson born 27 april... |\n",
       "| cathy caruth born 1955 is ... |\n",
       "| ian mitchell is a scottish... |\n",
       "| theodore preston hill born... |\n",
       "| steven weil is an american... |\n",
       "| rob sheffield born februar... |\n",
       "| professor michel che born ... |\n",
       "| for a hong kong entreprene... |\n",
       "| susan christie is an ameri... |\n",
       "| quintin e primo iii born m... |\n",
       "+-------------------------------+\n",
       "[? rows x 3 columns]\n",
       "Note: Only the head of the SFrame is printed. This SFrame is lazily evaluated.\n",
       "You can use sf.materialize() to force materialization."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki['tf_idf'] = tc.text_analytics.tf_idf(wiki['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">URI</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">text</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">tf_idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Grant_Nelson&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Grant Nelson</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">grant nelson born 27<br>april 1971 in london  ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'houston':<br>3.848936004850463, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Cathy_Caruth&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Cathy Caruth</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">cathy caruth born 1955 is<br>frank h t rhodes ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'phenomenon':<br>5.827907016166664, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Ian_Mitchell_(aut ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Ian Mitchell (author)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">ian mitchell is a<br>scottish author who grew ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'office':<br>2.667158932916311, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Ted_Hill_(mathema ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Ted Hill (mathematician)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">theodore preston hill<br>born december 28 1943 is ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'operations':<br>3.755845581784451, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Steven_Weil&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Steven Weil</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">steven weil is an<br>american rabbi who grew ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'rabbi':<br>24.088252122430486, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Rob_Sheffield&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Rob Sheffield</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">rob sheffield born<br>february 2 1966 is an ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'gq': 6.096171002761344,<br>'true': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Michel_Che&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Michel Che</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">professor michel che born<br>in lyon france completed ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'particularly':<br>3.6706877734441443, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Vincent_Fang_(lyr ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Vincent Fang (lyricist)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">for a hong kong<br>entrepreneur please r ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'chinese':<br>22.624627392006758, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Susan_Christie&gt; ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Susan Christie</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">susan christie is an<br>american singersongwr ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'weavers':<br>7.967973179662935, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">&lt;http://dbpedia.org/resou<br>rce/Quintin_E._Primo_ ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Quintin E. Primo III</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">quintin e primo iii born<br>march 14 1955 is the ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'limited':<br>15.083084928004507, ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[5774 rows x 4 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tURI\tstr\n",
       "\tname\tstr\n",
       "\ttext\tstr\n",
       "\ttf_idf\tdict\n",
       "\n",
       "Rows: 5774\n",
       "\n",
       "Data:\n",
       "+-------------------------------+--------------------------+\n",
       "|              URI              |           name           |\n",
       "+-------------------------------+--------------------------+\n",
       "| <http://dbpedia.org/resour... |       Grant Nelson       |\n",
       "| <http://dbpedia.org/resour... |       Cathy Caruth       |\n",
       "| <http://dbpedia.org/resour... |  Ian Mitchell (author)   |\n",
       "| <http://dbpedia.org/resour... | Ted Hill (mathematician) |\n",
       "| <http://dbpedia.org/resour... |       Steven Weil        |\n",
       "| <http://dbpedia.org/resour... |      Rob Sheffield       |\n",
       "| <http://dbpedia.org/resour... |        Michel Che        |\n",
       "| <http://dbpedia.org/resour... | Vincent Fang (lyricist)  |\n",
       "| <http://dbpedia.org/resour... |      Susan Christie      |\n",
       "| <http://dbpedia.org/resour... |   Quintin E. Primo III   |\n",
       "+-------------------------------+--------------------------+\n",
       "+-------------------------------+-------------------------------+\n",
       "|              text             |             tf_idf            |\n",
       "+-------------------------------+-------------------------------+\n",
       "| grant nelson born 27 april... | {'houston': 3.848936004850... |\n",
       "| cathy caruth born 1955 is ... | {'phenomenon': 5.827907016... |\n",
       "| ian mitchell is a scottish... | {'office': 2.6671589329163... |\n",
       "| theodore preston hill born... | {'operations': 3.755845581... |\n",
       "| steven weil is an american... | {'rabbi': 24.0882521224304... |\n",
       "| rob sheffield born februar... | {'gq': 6.096171002761344, ... |\n",
       "| professor michel che born ... | {'particularly': 3.6706877... |\n",
       "| for a hong kong entreprene... | {'chinese': 22.62462739200... |\n",
       "| susan christie is an ameri... | {'weavers': 7.967973179662... |\n",
       "| quintin e primo iii born m... | {'limited': 15.08308492800... |\n",
       "+-------------------------------+-------------------------------+\n",
       "[5774 rows x 4 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remainder of the assignment, we will use sparse matrices. Sparse matrices are matrices that have a small number of nonzero entries. A good data structure for sparse matrices would only store the nonzero entries to save space and speed up computation. SciPy provides a highly-optimized library for sparse matrices. Many matrix operations available for NumPy arrays are also available for SciPy sparse matrices.\n",
    "\n",
    "We first convert the TF-IDF column (in dictionary format) into the SciPy sparse matrix format. We included plenty of comments for the curious; if you'd like, you may skip the next block and treat the function as a black box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sframe_to_scipy(x, column_name):\n",
    "    '''\n",
    "    Convert a dictionary column of an SFrame into a sparse matrix format where\n",
    "    each (row_id, column_id, value) triple corresponds to the value of\n",
    "    x[row_id][column_id], where column_id is a key in the dictionary.\n",
    "       \n",
    "    Example\n",
    "    >>> sparse_matrix, map_key_to_index = sframe_to_scipy(sframe, column_name)\n",
    "    '''\n",
    "    assert x[column_name].dtype() == {}, \\\n",
    "    'The chosen column must be dict type, representing sparse data.'\n",
    "        \n",
    "    # Create triples of (row_id, feature_id, count).\n",
    "    # 1. Add a row number.\n",
    "    x = x.add_row_number()\n",
    "    # 2. Stack will transform x to have a row for each unique (row, key) pair.\n",
    "    x = x.stack(column_name, ['feature', 'value'])\n",
    "\n",
    "    keys = x['feature'].unique()\n",
    "    encoding = {k:i for i, k in enumerate(keys)}\n",
    "    # Apply the mapping\n",
    "    x['feature_id'] = x['feature'].apply(lambda key: encoding[key])\n",
    "\n",
    "    # Create numpy arrays that contain the data for the sparse matrix.\n",
    "    i = np.array(x['id'])\n",
    "    j = np.array(x['feature_id'])\n",
    "    v = np.array(x['value'])\n",
    "    width = x['id'].max() + 1\n",
    "    height = x['feature_id'].max() + 1\n",
    "\n",
    "    # Create a sparse matrix.\n",
    "    mat = csr_matrix((v, (i, j)), shape=(width, height))\n",
    "\n",
    "    return mat, {i:k for i, k in enumerate(keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Using default 16 lambda workers.</pre>"
      ],
      "text/plain": [
       "Using default 16 lambda workers."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>To maximize the degree of parallelism, add the following code to the beginning of the program:</pre>"
      ],
      "text/plain": [
       "To maximize the degree of parallelism, add the following code to the beginning of the program:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>\"turicreate.config.set_runtime_config('TURI_DEFAULT_NUM_PYLAMBDA_WORKERS', 24)\"</pre>"
      ],
      "text/plain": [
       "\"turicreate.config.set_runtime_config('TURI_DEFAULT_NUM_PYLAMBDA_WORKERS', 24)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Note that increasing the degree of parallelism also increases the memory footprint.</pre>"
      ],
      "text/plain": [
       "Note that increasing the degree of parallelism also increases the memory footprint."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The conversion will take about a minute or two.\n",
    "tf_idf, map_index_to_word = sframe_to_scipy(wiki, 'tf_idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5774x110013 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1017753 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above matrix contains a TF-IDF score for each of the 5774 pages in the data set and each of the 110013 unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize all vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the previous assignment, Euclidean distance can be a poor metric of similarity between documents, as it unfairly penalizes long articles. For a reasonable assessment of similarity, we should disregard the length information and use length-agnostic metrics, such as cosine distance.\n",
    "\n",
    "The k-means algorithm does not directly work with cosine distance, so we take an alternative route to remove length information: we normalize all vectors to be unit length. It turns out that Euclidean distance closely mimics cosine distance when all vectors are unit length. In particular, the squared Euclidean distance between any two vectors of length one is directly proportional to their cosine distance.\n",
    "\n",
    "We can prove this as follows. Let $\\mathbf{x}$ and $\\mathbf{y}$ be normalized vectors, i.e. unit vectors, so that $\\|\\mathbf{x}\\|=\\|\\mathbf{y}\\|=1$. Write the squared Euclidean distance as the dot product of $(\\mathbf{x} - \\mathbf{y})$ to itself:\n",
    "\\begin{align*}\n",
    "\\|\\mathbf{x} - \\mathbf{y}\\|^2 &= (\\mathbf{x} - \\mathbf{y})^T(\\mathbf{x} - \\mathbf{y})\\\\\n",
    "                              &= (\\mathbf{x}^T \\mathbf{x}) - 2(\\mathbf{x}^T \\mathbf{y}) + (\\mathbf{y}^T \\mathbf{y})\\\\\n",
    "                              &= \\|\\mathbf{x}\\|^2 - 2(\\mathbf{x}^T \\mathbf{y}) + \\|\\mathbf{y}\\|^2\\\\\n",
    "                              &= 2 - 2(\\mathbf{x}^T \\mathbf{y})\\\\\n",
    "                              &= 2(1 - (\\mathbf{x}^T \\mathbf{y}))\\\\\n",
    "                              &= 2\\left(1 - \\frac{\\mathbf{x}^T \\mathbf{y}}{\\|\\mathbf{x}\\|\\|\\mathbf{y}\\|}\\right)\\\\\n",
    "                              &= 2\\left[\\text{cosine distance}\\right]\n",
    "\\end{align*}\n",
    "\n",
    "This tells us that two **unit vectors** that are close in Euclidean distance are also close in cosine distance. Thus, the k-means algorithm (which naturally uses Euclidean distances) on normalized vectors will produce the same results as clustering using cosine distance as a distance metric.\n",
    "\n",
    "We import the [`normalize()` function](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html) from scikit-learn to normalize all vectors to unit length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "tf_idf = normalize(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement the k-means algorithm. First, we choose an initial set of centroids. A common practice is to choose randomly from the data points.\n",
    "\n",
    "**Note:** We specify a seed here, so that everyone gets the same answer. In practice, we highly recommend to use different seeds every time (for instance, by using the current timestamp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_centroids(data, k, seed=None):\n",
    "    '''Randomly choose k data points as initial centroids'''\n",
    "    if seed is not None: # useful for obtaining consistent results\n",
    "        np.random.seed(seed)\n",
    "    n = data.shape[0] # number of data points\n",
    "        \n",
    "    # Pick K indices from range [0, N).\n",
    "    rand_indices = np.random.randint(0, n, k)\n",
    "    \n",
    "    # Keep centroids as dense format, as many entries will be nonzero due to averaging.\n",
    "    # As long as at least one document in a cluster contains a word,\n",
    "    # it will carry a nonzero weight in the TF-IDF vector of the centroid.\n",
    "    centroids = data[rand_indices,:].toarray()\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialization, the k-means algorithm iterates between the following two steps:\n",
    "1. Assign each data point to the closest centroid.\n",
    "$$\n",
    "z_i \\gets \\mathrm{argmin}_j \\|\\mu_j - \\mathbf{x}_i\\|^2\n",
    "$$\n",
    "2. Revise centroids as the mean of the assigned data points.\n",
    "$$\n",
    "\\mu_j \\gets \\frac{1}{n_j}\\sum_{i:z_i=j} \\mathbf{x}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pseudocode, we iteratively do the following:\n",
    "```\n",
    "cluster_assignment = assign_clusters(data, centroids)\n",
    "centroids = revise_centroids(data, k, cluster_assignment)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we implement Step 1 of the main k-means loop above? First import `pairwise_distances` function from scikit-learn, which calculates Euclidean distances between rows of given arrays. See [this documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html) for more information.\n",
    "\n",
    "For the sake of demonstration, let's look at documents 100 through 102 as query documents and compute the distances between each of these documents and every other document in the corpus. In the k-means algorithm, we will have to compute pairwise distances between the set of centroids and the set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.41068657 1.41126417]\n",
      " [1.40838656 1.41044618]\n",
      " [1.41150978 1.41152872]\n",
      " ...\n",
      " [1.40698593 1.39992816]\n",
      " [1.40540087 1.39464441]\n",
      " [1.41090819 1.4060136 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Get the TF-IDF vectors for documents 100 through 102.\n",
    "queries = tf_idf[100:102,:]\n",
    "\n",
    "# Compute pairwise distances from every data point to each query vector.\n",
    "dist = pairwise_distances(tf_idf, queries, metric='euclidean')\n",
    "\n",
    "print dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5774, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More formally, `dist[i,j]` is assigned the distance between the `i`th row of `X` (i.e., `X[i,:]`) and the `j`th row of `Y` (i.e., `Y[j,:]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** For a moment, suppose that we initialize three centroids with the first 3 rows of `tf_idf`. Write code to compute pairwise distances from each of the centroids (which we're initializing as the first 3 rows) to all data points in `tf_idf`, and save it `distances`. Then find the distance between row 430 of `tf_idf` and the second centroid by extracting it from `distances` and save it to `dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students should write code here\n",
    "queries = tf_idf[0:3,:]\n",
    "distances = pairwise_distances(tf_idf, queries, metric='euclidean')\n",
    "dist = distances[430,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5774, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "'''Test cell'''\n",
    "if np.allclose(dist, pairwise_distances(tf_idf[430,:], tf_idf[1,:])):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Next, given the pairwise distances, we take the minimum of the distances for each data point. Fittingly, NumPy provides an `argmin` function. See [this documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.argmin.html) for details.\n",
    "\n",
    "Read the documentation and write code to produce a 1D array whose i-th entry indicates the centroid that is the closest to the i-th data point. Use the list of distances from the previous checkpoint. Following the theme of this case study, we will judge whether the clustering makes sense in the context of document analysis.. Save this array as `closest_cluster`.\n",
    "\n",
    "**Hint:** the resulting array should be as long as the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5774,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Students should write code here\n",
    "closest_cluster = np.argmin(distances, axis = 1)\n",
    "closest_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[4, 1, 2], \n",
    "   [3, 4, 5],\n",
    "   [5, 5, 0]]\n",
    "np.argmin(a, axis = 0)   \n",
    "# returns index of the smallest column down each row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(a, axis = 1)    #returns index of the smallest row in each col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "'''Test cell'''\n",
    "reference = [list(row).index(min(row)) for row in distances]\n",
    "if np.allclose(closest_cluster, reference):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Let's put these steps together.  First, initialize three centroids with the first 3 rows of `tf_idf`. Then, compute distances from each of the centroids to all data points in `tf_idf`. Finally, use these distance calculations to compute cluster assignments and assign them to `cluster_assignment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students should write code here\n",
    "cluster_assignment = closest_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "if len(cluster_assignment)==5774 and \\\n",
    "   np.array_equal(np.bincount(cluster_assignment), np.array([1476, 1562, 2736])):\n",
    "    print('Pass') # count number of data points for each cluster\n",
    "else:\n",
    "    print('Check your code again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fill in the blanks the function `assign_clusters(data, centroids)`. \n",
    "\n",
    "Parameters:  \n",
    " - `data` - is an `np.array` of `float` values of length `N`.  \n",
    " - `centroids` - is an `np.array` of `float` values of length `k`.\n",
    "\n",
    "Returns  \n",
    "-  A `np.array` of length `N` where the `i`th index represents which centroid `data[i]` was assigned to. The assignments range between the values `0, ..., k-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_clusters(data, centroids):\n",
    "    \n",
    "    # Compute distances between each data point and the set of centroids:\n",
    "    distances_from_centroids = pairwise_distances(data, centroids, metric='euclidean')\n",
    "    \n",
    "    # Compute cluster assignments for each data point:\n",
    "    cluster_assignment = np.argmin(distances_from_centroids, axis = 1)\n",
    "    \n",
    "    return cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**. For the last time, let us check if Step 1 was implemented correctly. With rows 0, 2, 4, and 6 of `tf_idf` as an initial set of centroids, we assign cluster labels to rows 0, 10, 20, ..., and 90 of `tf_idf`. The resulting cluster labels should be `[0, 1, 1, 0, 0, 2, 0, 2, 2, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "if np.allclose(assign_clusters(tf_idf[0:100:10], tf_idf[0:8:2]), np.array([0, 3, 3, 0, 3, 0, 2, 3, 0, 0])):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revising clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn to Step 2, where we compute the new centroids given the cluster assignments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy and NumPy arrays allow for filtering via Boolean masks. For instance, we filter all data points that are assigned to cluster 0 by writing\n",
    "```\n",
    "data[cluster_assignment==0,:]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develop intuition about filtering, let's look at a toy example consisting of 3 data points and 2 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1., 2., 0.],\n",
    "                 [0., 0., 0.],\n",
    "                 [2., 2., 0.]])\n",
    "centroids = np.array([[0.5, 0.5, 0.],\n",
    "                      [0., -0.5, 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign these data points to the closest centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "cluster_assignment = assign_clusters(data, centroids)\n",
    "print cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression `cluster_assignment==1` gives a list of Booleans that says whether each data point is assigned to cluster 1 or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise for cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lieu of indices, we can put in the list of Booleans to pick and choose rows. Only the rows that correspond to a `True` entry will be retained.\n",
    "\n",
    "First, let's look at the data points (i.e., their values) assigned to cluster 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense since [0 0 0] is closer to [0 -0.5 0] than to [0.5 0.5 0].\n",
    "\n",
    "Now let's look at the data points assigned to cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 0.],\n",
       "       [2., 2., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this makes sense since these values are each closer to [0.5 0.5 0] than to [0 -0.5 0].\n",
    "\n",
    "Given all the data points in a cluster, it only remains to compute the mean. Use [np.mean()](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.mean.html). By default, the function averages all elements in a 2D array. To compute row-wise or column-wise means, add the `axis` argument. See the linked documentation for details. \n",
    "\n",
    "Use this function to average the data points in cluster 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 2. , 0. ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cluster_assignment==0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fill in the blanks the function `revise_centroids(data, k, cluster_assignment)`. \n",
    "\n",
    "Parameters:  \n",
    " - `data` - is an `np.array` of `float` values of length `N`.\n",
    " - `k` - number of centroids\n",
    " - `cluster_assignment` - `np.array` of length `N` where the `i`th index represents which centroid `data[i]` was assigned to. The assignments range between the values `0, ..., k-1`.\n",
    "\n",
    "Returns  \n",
    "-  A `np.array` of length `k` for the new centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_centroids(data, k, cluster_assignment):\n",
    "    new_centroids = []\n",
    "    for i in xrange(k):\n",
    "        # Select all data points that belong to cluster i. Fill in the blank (RHS only)\n",
    "        member_data_points = data[cluster_assignment == i,:]\n",
    "        # Compute the mean of the data points. Fill in the blank (RHS only)\n",
    "        centroid = member_data_points.mean(axis=0)\n",
    "        \n",
    "        # Convert numpy.matrix type to numpy.ndarray type\n",
    "        centroid = centroid.A1\n",
    "        new_centroids.append(centroid)\n",
    "    new_centroids = np.array(new_centroids)\n",
    "    \n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**. Let's check our Step 2 implementation. Letting rows 0, 10, ..., 100 of `tf_idf` as the data points and the cluster labels `[0, 1, 1, 0, 0, 2, 0, 2, 2, 1]`, we compute the next set of centroids. Each centroid is given by the average of all member data points in corresponding cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "result = revise_centroids(tf_idf[0:100:10], 3, np.array([0, 1, 1, 0, 0, 2, 0, 2, 2, 1]))\n",
    "if np.allclose(result[0], np.mean(tf_idf[[0,30,40,60]].toarray(), axis=0)) and \\\n",
    "   np.allclose(result[1], np.mean(tf_idf[[10,20,90]].toarray(), axis=0))   and \\\n",
    "   np.allclose(result[2], np.mean(tf_idf[[50,70,80]].toarray(), axis=0)):\n",
    "    print('Pass')\n",
    "else:\n",
    "    print('Check your code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we tell if the k-means algorithm is converging? We can look at the cluster assignments and see if they stabilize over time. In fact, we'll be running the algorithm until the cluster assignments stop changing at all. To be extra safe, and to assess the clustering performance, we'll be looking at an additional criteria: the sum of all squared distances between data points and centroids. This is defined as\n",
    "$$\n",
    "J(\\mathcal{Z},\\mu) = \\sum_{j=1}^k \\sum_{i:z_i = j} \\|\\mathbf{x}_i - \\mu_j\\|^2.\n",
    "$$\n",
    "The smaller the distances, the more homogeneous the clusters are. In other words, we'd like to have \"tight\" clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_heterogeneity(data, k, centroids, cluster_assignment):\n",
    "    \n",
    "    heterogeneity = 0.0\n",
    "    for i in xrange(k):\n",
    "        \n",
    "        # Select all data points that belong to cluster i. Fill in the blank (RHS only)\n",
    "        member_data_points = data[cluster_assignment==i,:]\n",
    "        \n",
    "        if member_data_points.shape[0] > 0: # check if i-th cluster is non-empty\n",
    "            # Compute distances from centroid to data point\n",
    "            distances = pairwise_distances(member_data_points, [centroids[i]], metric='euclidean')\n",
    "            squared_distances = distances**2\n",
    "            heterogeneity += np.sum(squared_distances)\n",
    "        \n",
    "    return heterogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the cluster heterogeneity for the 2-cluster example we've been considering based on our current cluster assignments and centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_heterogeneity(data, 2, centroids, cluster_assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining into a single function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the two k-means steps have been implemented, as well as our heterogeneity metric we wish to monitor, it is only a matter of putting these functions together to write a k-means algorithm that\n",
    "\n",
    "* Repeatedly performs Steps 1 and 2\n",
    "* Tracks convergence metrics\n",
    "* Stops if either no assignment changed or we reach a certain number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fill in the blanks the function `kmeans(data, k, initial_centroids, maxiter, record_heterogeneity=None, verbose=False)`. \n",
    "\n",
    "Parameters:  \n",
    " - `data` - is an `np.array` of `float` values of length `N`.\n",
    " - `k` - number of centroids\n",
    " - `initial_centroids` - is an `np.array` of `float` values of length `k`.\n",
    " - `maxiter` - maximum number of iterations to run the algorithm\n",
    " - `record_heterogeneity` - if provided an empty list, it will compute the heterogeneity at each iteration and append it to the list. Defaults to `None` and won't record heterogeneity.\n",
    " - `verbose` - set to True to display progress. Defaults to `False` and won't display progress.\n",
    "\n",
    "Returns  \n",
    "- `centroids` - A `np.array` of length `k` for the centroids upon termination of the algorithm.\n",
    "- `cluster_assignment` - A `np.array` of length `N` where the `i`th index represents which centroid `data[i]` was assigned to. The assignments range between the values `0, ..., k-1` upon termination of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the blanks\n",
    "def kmeans(data, k, initial_centroids, maxiter, record_heterogeneity=None, verbose=False):\n",
    "    '''This function runs k-means on given data and initial set of centroids.\n",
    "       maxiter: maximum number of iterations to run.\n",
    "       record_heterogeneity: (optional) a list, to store the history of heterogeneity as function of iterations\n",
    "                             if None, do not store the history.\n",
    "       verbose: if True, print how many data points changed their cluster labels in each iteration'''\n",
    "    centroids = initial_centroids[:]\n",
    "    prev_cluster_assignment = None\n",
    "    \n",
    "    for itr in xrange(maxiter):        \n",
    "        if verbose:\n",
    "            print(itr)\n",
    "\n",
    "    \n",
    "        # 1. Make cluster assignments using nearest centroids\n",
    "        cluster_assignment = assign_clusters(data, centroids)\n",
    "            \n",
    "        # 2. Compute a new centroid for each of the k clusters, averaging all data points assigned to that cluster.\n",
    "        centroids = revise_centroids(data, k, cluster_assignment)\n",
    "            \n",
    "        # Check for convergence: if none of the assignments changed, stop\n",
    "        if prev_cluster_assignment is not None and \\\n",
    "          (prev_cluster_assignment==cluster_assignment).all():\n",
    "            break\n",
    "        \n",
    "        # Print number of new assignments \n",
    "        if prev_cluster_assignment is not None:\n",
    "            num_changed = sum(abs(prev_cluster_assignment-cluster_assignment))\n",
    "            if verbose:\n",
    "                print('    {0:5d} elements changed their cluster assignment.'.format(num_changed)) \n",
    "                \n",
    "        \n",
    "        # Record heterogeneity convergence metric\n",
    "        if record_heterogeneity is not None:\n",
    "            score = compute_heterogeneity(data, k, centroids, cluster_assignment)\n",
    "            record_heterogeneity.append(score)\n",
    "        \n",
    "        prev_cluster_assignment = cluster_assignment[:]\n",
    "        \n",
    "    return centroids, cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting convergence metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the above function to plot the convergence metric across iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heterogeneity(heterogeneity, k):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(heterogeneity, linewidth=4)\n",
    "    plt.xlabel('# Iterations')\n",
    "    plt.ylabel('Heterogeneity')\n",
    "    plt.title('Heterogeneity of clustering over time, K={0:d}'.format(k))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider running k-means with K=3 clusters for a maximum of 400 iterations, recording cluster heterogeneity at every step.  Then, let's plot the heterogeneity over iterations using the plotting function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "     1901 elements changed their cluster assignment.\n",
      "2\n",
      "      881 elements changed their cluster assignment.\n",
      "3\n",
      "      654 elements changed their cluster assignment.\n",
      "4\n",
      "      251 elements changed their cluster assignment.\n",
      "5\n",
      "      140 elements changed their cluster assignment.\n",
      "6\n",
      "       75 elements changed their cluster assignment.\n",
      "7\n",
      "       37 elements changed their cluster assignment.\n",
      "8\n",
      "       29 elements changed their cluster assignment.\n",
      "9\n",
      "       25 elements changed their cluster assignment.\n",
      "10\n",
      "       21 elements changed their cluster assignment.\n",
      "11\n",
      "       18 elements changed their cluster assignment.\n",
      "12\n",
      "       13 elements changed their cluster assignment.\n",
      "13\n",
      "       17 elements changed their cluster assignment.\n",
      "14\n",
      "       18 elements changed their cluster assignment.\n",
      "15\n",
      "       24 elements changed their cluster assignment.\n",
      "16\n",
      "       26 elements changed their cluster assignment.\n",
      "17\n",
      "       16 elements changed their cluster assignment.\n",
      "18\n",
      "       19 elements changed their cluster assignment.\n",
      "19\n",
      "       25 elements changed their cluster assignment.\n",
      "20\n",
      "       15 elements changed their cluster assignment.\n",
      "21\n",
      "       11 elements changed their cluster assignment.\n",
      "22\n",
      "       10 elements changed their cluster assignment.\n",
      "23\n",
      "       13 elements changed their cluster assignment.\n",
      "24\n",
      "        9 elements changed their cluster assignment.\n",
      "25\n",
      "        9 elements changed their cluster assignment.\n",
      "26\n",
      "        8 elements changed their cluster assignment.\n",
      "27\n",
      "        8 elements changed their cluster assignment.\n",
      "28\n",
      "        6 elements changed their cluster assignment.\n",
      "29\n",
      "        6 elements changed their cluster assignment.\n",
      "30\n",
      "        5 elements changed their cluster assignment.\n",
      "31\n",
      "        7 elements changed their cluster assignment.\n",
      "32\n",
      "       10 elements changed their cluster assignment.\n",
      "33\n",
      "        2 elements changed their cluster assignment.\n",
      "34\n",
      "        2 elements changed their cluster assignment.\n",
      "35\n",
      "        1 elements changed their cluster assignment.\n",
      "36\n",
      "        2 elements changed their cluster assignment.\n",
      "37\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 3\n",
    "heterogeneity = []\n",
    "initial_centroids = get_initial_centroids(tf_idf, k, seed=0)\n",
    "centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, maxiter=400,\n",
    "                                       record_heterogeneity=heterogeneity, verbose=True)\n",
    "plot_heterogeneity(heterogeneity, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. (True/False) The clustering objective (heterogeneity) is non-increasing for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Let's step back from this particular example. If the clustering objective (heterogeneity) would ever increase when running k-means, that would indicate: (choose one)\n",
    "\n",
    "1. k-means algorithm got stuck in a bad local minimum\n",
    "2. There is a bug in the k-means code\n",
    "3. All data points consist of exact duplicates\n",
    "4. Nothing is wrong. The objective should generally go down sooner or later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Which of the cluster contains the greatest number of data points in the end? Hint: Use [`np.bincount()`](http://docs.scipy.org/doc/numpy-1.11.0/reference/generated/numpy.bincount.html) to count occurrences of each cluster label.\n",
    " 1. Cluster #0\n",
    " 2. Cluster #1\n",
    " 3. Cluster #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1126, 1919, 2729])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(cluster_assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beware of local maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One weakness of k-means is that it tends to get stuck in a local minimum. To see this, let us run k-means multiple times, with different initial centroids created using different random seeds.\n",
    "\n",
    "**Note:** Again, in practice, you should set different seeds for every run. We give you a list of seeds for this assignment so that everyone gets the same answer.\n",
    "\n",
    "This may take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=000000, heterogeneity=5597.40178\n",
      "seed=020000, heterogeneity=5604.30082\n",
      "seed=040000, heterogeneity=5599.33500\n",
      "seed=060000, heterogeneity=5600.55323\n",
      "seed=080000, heterogeneity=5593.77701\n",
      "seed=100000, heterogeneity=5593.91355\n",
      "seed=120000, heterogeneity=5598.51115\n",
      "17.3989219666\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "heterogeneity = {}\n",
    "import time\n",
    "start = time.time()\n",
    "for seed in [0, 20000, 40000, 60000, 80000, 100000, 120000]:\n",
    "    initial_centroids = get_initial_centroids(tf_idf, k, seed)\n",
    "    centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, maxiter=400,\n",
    "                                           record_heterogeneity=None, verbose=False)\n",
    "    # To save time, compute heterogeneity only once in the end\n",
    "    heterogeneity[seed] = compute_heterogeneity(tf_idf, k, centroids, cluster_assignment)\n",
    "    print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity[seed]))\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the variation in heterogeneity for different initializations. This indicates that k-means sometimes gets stuck at a bad local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One effective way to counter this tendency is to use **k-means++** to provide a smart initialization. This method tries to spread out the initial set of centroids so that they are not too close together. It is known to improve the quality of local optima and lower average runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_initialize(data, k, seed=None):\n",
    "    '''Use k-means++ to initialize a good set of centroids'''\n",
    "    if seed is not None: # useful for obtaining consistent results\n",
    "        np.random.seed(seed)\n",
    "    centroids = np.zeros((k, data.shape[1]))\n",
    "    \n",
    "    # Randomly choose the first centroid.\n",
    "    # Since we have no prior knowledge, choose uniformly at random\n",
    "    idx = np.random.randint(data.shape[0])\n",
    "    centroids[0] = data[idx,:].toarray()\n",
    "    # Compute distances from the first centroid chosen to all the other data points\n",
    "    distances = pairwise_distances(data, centroids[0:1], metric='euclidean').flatten()\n",
    "    \n",
    "    for i in xrange(1, k):\n",
    "        # Choose the next centroid randomly, so that the probability for each data point to be chosen\n",
    "        # is directly proportional to its squared distance from the nearest centroid.\n",
    "        # Roughtly speaking, a new centroid should be as far as from ohter centroids as possible.\n",
    "        idx = np.random.choice(data.shape[0], 1, p=distances/sum(distances))\n",
    "        centroids[i] = data[idx,:].toarray()\n",
    "        # Now compute distances from the centroids to all data points\n",
    "        distances = np.min(pairwise_distances(data, centroids[0:i+1], metric='euclidean'),axis=1)\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now rerun k-means with 10 clusters using the same set of seeds, but always using k-means++ to initialize the algorithm.\n",
    "\n",
    "This may take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=000000, heterogeneity=5594.15498\n",
      "seed=020000, heterogeneity=5593.14744\n",
      "seed=040000, heterogeneity=5595.40313\n",
      "seed=060000, heterogeneity=5595.68053\n",
      "seed=080000, heterogeneity=5598.66627\n",
      "seed=100000, heterogeneity=5599.06461\n",
      "seed=120000, heterogeneity=5595.91635\n",
      "16.6025929451\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "heterogeneity_smart = {}\n",
    "start = time.time()\n",
    "for seed in [0, 20000, 40000, 60000, 80000, 100000, 120000]:\n",
    "    initial_centroids = smart_initialize(tf_idf, k, seed)\n",
    "    centroids, cluster_assignment = kmeans(tf_idf, k, initial_centroids, maxiter=400,\n",
    "                                           record_heterogeneity=None, verbose=False)\n",
    "    # To save time, compute heterogeneity only once in the end\n",
    "    heterogeneity_smart[seed] = compute_heterogeneity(tf_idf, k, centroids, cluster_assignment)\n",
    "    print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity_smart[seed]))\n",
    "    sys.stdout.flush()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the set of cluster heterogeneities we got from our 7 restarts of k-means using random initialization compared to the 7 restarts of k-means using k-means++ as a smart initialization.\n",
    "\n",
    "The following code produces a [box plot](http://matplotlib.org/api/pyplot_api.html) for each of these methods, indicating the spread of values produced by each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.boxplot([heterogeneity.values(), heterogeneity_smart.values()], vert=False)\n",
    "plt.yticks([1, 2], ['k-means', 'k-means++'])\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice from the box plot:\n",
    "* Random initialization results in a worse clustering than k-means++ on average.\n",
    "* The best result of k-means++ is better than the best result of random initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In general, you should run k-means at least a few times with different initializations and then return the run resulting in the lowest heterogeneity.** Let us write a function that runs k-means multiple times and picks the best run that minimizes heterogeneity. The function accepts an optional list of seed values to be used for the multiple runs; if no such list is provided, the current UTC time is used as seed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fill in the blanks the function `kmeans_multiple_runs(data, k, maxiter, verbose=False)`. \n",
    "\n",
    "Parameters:  \n",
    " - `data` - is an `np.array` of `float` values of length `N`.\n",
    " - `k` - number of centroids\n",
    " - `maxiter` - maximum number of iterations to run the algorithm\n",
    " - `verbose` - set to True to display progress. Defaults to `False` and won't display progress.\n",
    "\n",
    "Returns  \n",
    "- `final_centroids` - A `np.array` of length `k` for the centroids upon termination of the algorithm.\n",
    "- `final_cluster_assignment` - A `np.array` of length `N` where the `i`th index represents which centroid `data[i]` was assigned to. The assignments range between the values `0, ..., k-1` upon termination of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_multiple_runs(data, k, maxiter, verbose=False):\n",
    "    heterogeneity = {}\n",
    "    \n",
    "    min_heterogeneity_achieved = float('inf')\n",
    "    best_seed = None\n",
    "    final_centroids = None\n",
    "    final_cluster_assignment = None\n",
    "    seed_list = [0, 20000, 40000, 60000, 80000, 100000, 120000]\n",
    "    num_runs = len(seed_list)\n",
    "    \n",
    "    for seed in seed_list:\n",
    "        \n",
    "        # Use k-means++ initialization: Fill in the blank\n",
    "        # Set record_heterogeneity=None because we will compute that once\n",
    "        initial_centroids = smart_initialize(data, k, seed=seed)\n",
    "        \n",
    "        # Run k-means: Fill in the blank \n",
    "        centroids, cluster_assignment = kmeans(data, k, initial_centroids, maxiter, record_heterogeneity=None, verbose=False)\n",
    "        \n",
    "        # To save time, compute heterogeneity only once in the end\n",
    "        # Fill in the blank on the right\n",
    "        heterogeneity[seed] = compute_heterogeneity(data, k, centroids, cluster_assignment)\n",
    "        \n",
    "        if verbose:\n",
    "            print('seed={0:06d}, heterogeneity={1:.5f}'.format(seed, heterogeneity[seed]))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        # if current measurement of heterogeneity is lower than previously seen,\n",
    "        # update the minimum record of heterogeneity.\n",
    "        if heterogeneity[seed] < min_heterogeneity_achieved:\n",
    "            min_heterogeneity_achieved = heterogeneity[seed]\n",
    "            best_seed = seed\n",
    "            final_centroids = centroids\n",
    "            final_cluster_assignment = cluster_assignment\n",
    "    \n",
    "    # Return the centroids and cluster assignments that minimize heterogeneity.\n",
    "    return final_centroids, final_cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are measuring the tightness of the clusters, a higher value of K reduces the possible heterogeneity metric by definition.  For example, if we have N data points and set K=N clusters, then we could have 0 cluster heterogeneity by setting the N centroids equal to the values of the N data points. (Note: Not all runs for larger K will result in lower heterogeneity than a single run with smaller K due to local optima.)  Let's explore this general trend for ourselves by performing the following analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `kmeans_multiple_runs` function to run k-means with five different values of K.  For each K, use k-means++ and multiple runs to pick the best solution.  In what follows, we consider K=2,10,25,50,100 and 7 restarts for each setting.\n",
    "\n",
    "\n",
    "**IMPORTANT: The code block below will take about 5-6 minutes to finish. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed=000000, heterogeneity=5675.70889\n",
      "seed=020000, heterogeneity=5679.97381\n",
      "seed=040000, heterogeneity=5679.17086\n",
      "seed=060000, heterogeneity=5679.19746\n",
      "seed=080000, heterogeneity=5679.63205\n",
      "seed=100000, heterogeneity=5679.55879\n",
      "seed=120000, heterogeneity=5679.18986\n",
      "seed=000000, heterogeneity=5594.15498\n",
      "seed=020000, heterogeneity=5593.14744\n",
      "seed=040000, heterogeneity=5595.40313\n",
      "seed=060000, heterogeneity=5595.68053\n",
      "seed=080000, heterogeneity=5598.66627\n",
      "seed=100000, heterogeneity=5599.06461\n",
      "seed=120000, heterogeneity=5595.91635\n",
      "seed=000000, heterogeneity=5535.68066\n",
      "seed=020000, heterogeneity=5531.99017\n",
      "seed=040000, heterogeneity=5533.56981\n",
      "seed=060000, heterogeneity=5535.05054\n",
      "seed=080000, heterogeneity=5538.11343\n",
      "seed=100000, heterogeneity=5521.55550\n",
      "seed=120000, heterogeneity=5535.61407\n",
      "seed=000000, heterogeneity=5475.14912\n",
      "seed=020000, heterogeneity=5483.48702\n",
      "seed=040000, heterogeneity=5466.64871\n",
      "seed=060000, heterogeneity=5464.76777\n",
      "seed=080000, heterogeneity=5466.33501\n",
      "seed=100000, heterogeneity=5471.63761\n",
      "seed=120000, heterogeneity=5469.31468\n",
      "seed=000000, heterogeneity=5398.58107\n",
      "seed=020000, heterogeneity=5393.26313\n",
      "seed=040000, heterogeneity=5383.74175\n",
      "seed=060000, heterogeneity=5385.66170\n",
      "seed=080000, heterogeneity=5384.38336\n",
      "seed=100000, heterogeneity=5401.32207\n",
      "seed=120000, heterogeneity=5401.20719\n",
      "350.456873894\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_k_vs_heterogeneity(k_values, heterogeneity_values):\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(k_values, heterogeneity_values, linewidth=4)\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Heterogeneity')\n",
    "    plt.title('K vs. Heterogeneity')\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()\n",
    "\n",
    "start = time.time()\n",
    "centroids = {}\n",
    "cluster_assignment = {}\n",
    "heterogeneity_values = []\n",
    "k_list = [2, 10, 25, 50, 100]\n",
    "\n",
    "for k in k_list:\n",
    "    heterogeneity = []\n",
    "    centroids[k], cluster_assignment[k] = kmeans_multiple_runs(tf_idf, k, maxiter=400,\n",
    "                                                               verbose=True)\n",
    "    score = compute_heterogeneity(tf_idf, k, centroids[k], cluster_assignment[k])\n",
    "    heterogeneity_values.append(score)\n",
    "\n",
    "plot_k_vs_heterogeneity(k_list, heterogeneity_values)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot we show that heterogeneity goes down as we increase the number of clusters. Does this mean we should always favor a higher K? **Not at all!** As we will see in the following section, setting K too high may end up separating data points that are actually pretty alike. At the extreme, we can set individual data points to be their own clusters (K=N) and achieve zero heterogeneity, but separating each data point into its own cluster is hardly a desirable outcome. In the following section, we will learn how to detect a K set \"too large\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize clusters of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start visualizing some clustering results to see if we think the clustering makes sense.  We can use such visualizations to help us assess whether we have set K too large or too small for a given application.  Following the theme of this course, we will judge whether the clustering makes sense in the context of document analysis.\n",
    "\n",
    "What are we looking for in a good clustering of documents?\n",
    "* Documents in the same cluster should be similar.\n",
    "* Documents from different clusters should be less similar.\n",
    "\n",
    "So a bad clustering exhibits either of two symptoms:\n",
    "* Documents in a cluster have mixed content.\n",
    "* Documents with similar content are divided up and put into different clusters.\n",
    "\n",
    "To help visualize the clustering, we do the following:\n",
    "* Fetch nearest neighbors of each centroid from the set of documents assigned to that cluster. We will consider these documents as being representative of the cluster.\n",
    "* Print titles and first sentences of those nearest neighbors.\n",
    "* Print top 5 words that have highest tf-idf weights in each centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_document_clusters(wiki, tf_idf, centroids, cluster_assignment, k, map_index_to_word, display_content=True):\n",
    "    '''wiki: original dataframe\n",
    "       tf_idf: data matrix, sparse matrix format\n",
    "       map_index_to_word: SFrame specifying the mapping betweeen words and column indices\n",
    "       display_content: if True, display 8 nearest neighbors of each centroid'''\n",
    "    \n",
    "    print('==========================================================')\n",
    "\n",
    "    # Visualize each cluster c\n",
    "    for c in xrange(k):\n",
    "        # Cluster heading\n",
    "        print('Cluster {0:d}    '.format(c)),\n",
    "        # Print top 5 words with largest TF-IDF weights in the cluster\n",
    "        idx = centroids[c].argsort()[::-1]\n",
    "        for i in xrange(5): # Print each word along with the TF-IDF weight\n",
    "            print('{0:s}:{1:.3f}'.format(map_index_to_word[idx[i]], centroids[c,idx[i]])),\n",
    "        print('')\n",
    "        \n",
    "        if display_content:\n",
    "            # Compute distances from the centroid to all data points in the cluster,\n",
    "            # and compute nearest neighbors of the centroids within the cluster.\n",
    "            distances = pairwise_distances(tf_idf, centroids[c].reshape(1, -1), metric='euclidean').flatten()\n",
    "            distances[cluster_assignment!=c] = float('inf') # remove non-members from consideration\n",
    "            nearest_neighbors = distances.argsort()\n",
    "            # For 8 nearest neighbors, print the title as well as first 180 characters of text.\n",
    "            # Wrap the text at 80-character mark.\n",
    "            for i in xrange(8):\n",
    "                text = ' '.join(wiki[nearest_neighbors[i]]['text'].split(None, 25)[0:25])\n",
    "                print('\\n* {0:50s} {1:.5f}\\n  {2:s}\\n  {3:s}'.format(wiki[nearest_neighbors[i]]['name'],\n",
    "                    distances[nearest_neighbors[i]], text[:90], text[90:180] if len(text) > 90 else ''))\n",
    "        print('==========================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first look at the 2 cluster case (K=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Cluster 0     he:0.016 his:0.011 music:0.010 university:0.010 season:0.010 \n",
      "\n",
      "* Justin Knoedler                                    0.98055\n",
      "  justin joseph knoedler born july 17 1980 in springfield illinois is a former major league \n",
      "  baseball catcherknoedler was originally drafted by the st louis cardinals\n",
      "\n",
      "* James A. Joseph                                    0.98149\n",
      "  james a joseph born 1935 is an american former diplomatjoseph is professor of the practice\n",
      "   of public policy studies at duke university and founder of\n",
      "\n",
      "* Sol Campbell                                       0.98223\n",
      "  sulzeer jeremiah sol campbell born 18 september 1974 is a former england international foo\n",
      "  tballer a central defender he had a 19year career playing in the\n",
      "\n",
      "* Mark McCall                                        0.98269\n",
      "  mark mccall born 29 november 1967 in bangor county down northern ireland is an irish forme\n",
      "  r rugby union player and former coach of ulster he\n",
      "\n",
      "* Kevin Houston                                      0.98291\n",
      "  kevin houston born c 1964 is a former american basketball player who is best known for lea\n",
      "  ding ncaa division i in scoring during his senior\n",
      "\n",
      "* Neil Grayson                                       0.98305\n",
      "  neil grayson born 1 november 1964 in york is an english footballer who last played as a st\n",
      "  riker for sutton towngraysons first club was local\n",
      "\n",
      "* James A. Paul                                      0.98307\n",
      "  james a paul born june 10 1941 is a writer and nonprofit executive who has worked througho\n",
      "  ut his career in the field of international relations\n",
      "\n",
      "* Alberto Blanco (poet)                              0.98316\n",
      "  alberto blanco is considered one of mexicos most important poets born in mexico city on fe\n",
      "  bruary 18 1951 he spent his childhood and adolescence in\n",
      "==========================================================\n",
      "Cluster 1     she:0.133 her:0.086 film:0.014 women:0.013 actress:0.012 \n",
      "\n",
      "* Danica d'Hondt                                     0.93823\n",
      "  danica dhondt born may 29 1939 is an englishborn canadian actress writer and businesswoman\n",
      "   a winner of the miss canada pageant in 1959 was born\n",
      "\n",
      "* Karen Alexander (singer)                           0.94017\n",
      "  karen alexander born 1946 was an american singersongwriter who had some success in the 197\n",
      "  0s she was born in los angeles california and grew up\n",
      "\n",
      "* Pat Studdy-Clift                                   0.94417\n",
      "  pat studdyclift is an australian author specialising in historical fiction and nonfictionb\n",
      "  orn in 1925 she lived in gunnedah until she was sent to a boarding\n",
      "\n",
      "* Talluri Rameshwari                                 0.94527\n",
      "  talluri rameshwari also known as rameshwari is an indian actress she was born and raised i\n",
      "  n andhra pradesh and spent her childhood in kakinada she\n",
      "\n",
      "* Tererai Trent                                      0.94640\n",
      "  tererai trent born c 1965 is a zimbabweanamerican woman whose unlikely educational success\n",
      "   has brought her international fame tererai trent was not allowed to go\n",
      "\n",
      "* Marika Lejon                                       0.94724\n",
      "  marika saralotta lejon born 3 october 1984 in stavanger is a norwegian composer and singer\n",
      "   she grew up in sgne in the south of norway\n",
      "\n",
      "* Makiko Tanaka                                      0.94944\n",
      "  makiko tanaka tanaka makiko born in nishiyama niigata january 14 1944 is a japanese politi\n",
      "  cian she is the daughter of former prime minister kakuei tanakatanaka\n",
      "\n",
      "* Mariko Peters                                      0.95045\n",
      "  mariko peters born april 22 1969 in berkeley california united states is a former dutch po\n",
      "  litician and civil servant as well as lawyer she was\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "visualize_document_clusters(wiki, tf_idf, centroids[2], cluster_assignment[2], 2, map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both clusters have mixed content, although clearly cluster 0 are all men and cluster 1 are all women:\n",
    "* Cluster 0: men, football, rugby, basketball, etc..\n",
    "* Cluster 1: women, policitians, artists, singers, etc..\n",
    "\n",
    "Top words of cluster 1 are mostly related to women, whereas top words of cluster 0 are mostly related to men.\n",
    "\n",
    "It would be better if we sub-divided into more categories. So let us use more clusters. How about `K=10`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Cluster 0     art:0.058 book:0.028 poetry:0.027 museum:0.027 gallery:0.026 \n",
      "\n",
      "* Thomas Lawson (artist)                             0.95479\n",
      "  thomas lawson born 1951 glasgow scotland is an artist writer and dean of the school of art\n",
      "   at california institute for the arts he has\n",
      "\n",
      "* Will Maclean                                       0.95615\n",
      "  a noted and established scottish artist and professor of art will maclean was born in inve\n",
      "  rness in 1941 he was a midshipman 195759 before attending\n",
      "\n",
      "* Steve Roden                                        0.95696\n",
      "  steve roden is an american sound and visual artist who pioneered the lowercase style of mu\n",
      "  sic where quiet usually unheard sounds are amplified to form\n",
      "\n",
      "* Kerri Sakamoto                                     0.95725\n",
      "  kerri sakamoto born 1960 is a canadian novelist her novels commonly deal with the experien\n",
      "  ce of japanese canadianssakamotos debut novel the electrical field 1998 won\n",
      "\n",
      "* Alberto Blanco (poet)                              0.95851\n",
      "  alberto blanco is considered one of mexicos most important poets born in mexico city on fe\n",
      "  bruary 18 1951 he spent his childhood and adolescence in\n",
      "\n",
      "* Gema Alava                                         0.95870\n",
      "  gema alava b 1973 madrid spain is an artist who lives and works in new york city her work \n",
      "  in the form of installation drawing\n",
      "\n",
      "* Cliff Eyland                                       0.95897\n",
      "  cliff eyland born 1954 is a canadian painter writer and curator he studied at holland coll\n",
      "  ege mount allison university and the nova scotia college of\n",
      "\n",
      "* Paul Resika                                        0.96014\n",
      "  paul resika born 1928 is an american painter was born and raised in new york city resika b\n",
      "  egan exhibiting his paintings in new york city\n",
      "==========================================================\n",
      "Cluster 1     music:0.106 orchestra:0.079 opera:0.052 symphony:0.049 piano:0.040 \n",
      "\n",
      "* Matthew Coorey                                     0.91606\n",
      "  matthew coorey born 25 october 1973 is an australian conductor based in the united kingdom\n",
      "  he began his conducting career in 2002 when he took up\n",
      "\n",
      "* Ivor Bolton                                        0.92455\n",
      "  ivor bolton born 17 may 1958 in blackrod england is an english conductor and harpsichordis\n",
      "  t he studied at clare college university of cambridge 197680 and\n",
      "\n",
      "* Robert Kapilow                                     0.92726\n",
      "  robert kapilow december 22 1952 is an american composer conductor and music commentator he\n",
      "   is a phi beta kappa graduate of yale university a graduate\n",
      "\n",
      "* Jon Manasse                                        0.92775\n",
      "  jon manasse is an american clarinetistmanasse studied clarinet at the juilliard school und\n",
      "  er david weber he won a prize in the international competition for clarinet\n",
      "\n",
      "* James Mark (musician)                              0.93254\n",
      "  dr james mark is an americanborn conductor clarinetist saxophonist arranger and educator b\n",
      "  ased in canada he is the conductor and music director of the prince\n",
      "\n",
      "* Josu de Solaun Soto                                0.93266\n",
      "  josu de solaun born october 27 1981 is a spanish classical music pianist and winner of the\n",
      "   first prize at the xiii george enescu international\n",
      "\n",
      "* Adam Stern (conductor)                             0.93523\n",
      "  adam stern born 1955 is an american conductor born in hollywood stern was trained at the c\n",
      "  alifornia institute of the arts in los angeles he\n",
      "\n",
      "* Roy Goodman                                        0.93620\n",
      "  roy goodman born 26 january 1951 is an english conductor and violinist specialising in the\n",
      "   performance and direction of early music he became internationally famous\n",
      "==========================================================\n",
      "Cluster 2     album:0.058 band:0.051 music:0.040 jazz:0.034 released:0.029 \n",
      "\n",
      "* Keith Urban                                        0.94974\n",
      "  keith lionel urban born 26 october 1967 is a new zealand born australian country music sin\n",
      "  ger songwriter guitarist entrepreneur and music competition judge in 1991\n",
      "\n",
      "* Mark de Clive-Lowe                                 0.95122\n",
      "  mark de clivelowe is a musician composer and producer originally from new zealand and now \n",
      "  based in los angeles california since 2009 after ten years\n",
      "\n",
      "* Stewart Levine                                     0.95420\n",
      "  stewart levine is an american record producer he has worked with such artists as the crusa\n",
      "  ders minnie riperton lionel richie simply red hugh masekela dr\n",
      "\n",
      "* John Etheridge                                     0.95774\n",
      "  john michael glyn etheridge born 12 january 1948 in lambeth south east london is a british\n",
      "   jazzfusion guitarist associated with the canterbury scenehe began playing\n",
      "\n",
      "* Matthew Hager                                      0.95792\n",
      "  matthew hager is a multi platinum american record producer musician and songwriteroriginal\n",
      "  ly from houston texas hager now lives in los angeles before moving to los\n",
      "\n",
      "* Rodney Franklin                                    0.96031\n",
      "  rodney franklin born september 16 1958 berkeley california is an american jazz pianist and\n",
      "   composerat the age of six he took jazz piano lessons at\n",
      "\n",
      "* John Ellis (South African musician)                0.96073\n",
      "  john ellis born 6 july 1972 is a south african singersongwriter and guitarist and former l\n",
      "  ead singer of the south african band tree63 he was\n",
      "\n",
      "* Matthew Mayfield                                   0.96154\n",
      "  matthew mayfield is an american singersongwriter from birmingham alabama originally the le\n",
      "  ad singer in the group moses mayfield which disbanded in 2008 matthew has moved\n",
      "==========================================================\n",
      "Cluster 3     she:0.148 her:0.096 women:0.014 actress:0.013 womens:0.012 \n",
      "\n",
      "* Danica d'Hondt                                     0.93349\n",
      "  danica dhondt born may 29 1939 is an englishborn canadian actress writer and businesswoman\n",
      "   a winner of the miss canada pageant in 1959 was born\n",
      "\n",
      "* Karen Alexander (singer)                           0.93486\n",
      "  karen alexander born 1946 was an american singersongwriter who had some success in the 197\n",
      "  0s she was born in los angeles california and grew up\n",
      "\n",
      "* Pat Studdy-Clift                                   0.94027\n",
      "  pat studdyclift is an australian author specialising in historical fiction and nonfictionb\n",
      "  orn in 1925 she lived in gunnedah until she was sent to a boarding\n",
      "\n",
      "* Talluri Rameshwari                                 0.94055\n",
      "  talluri rameshwari also known as rameshwari is an indian actress she was born and raised i\n",
      "  n andhra pradesh and spent her childhood in kakinada she\n",
      "\n",
      "* Tererai Trent                                      0.94148\n",
      "  tererai trent born c 1965 is a zimbabweanamerican woman whose unlikely educational success\n",
      "   has brought her international fame tererai trent was not allowed to go\n",
      "\n",
      "* Marika Lejon                                       0.94311\n",
      "  marika saralotta lejon born 3 october 1984 in stavanger is a norwegian composer and singer\n",
      "   she grew up in sgne in the south of norway\n",
      "\n",
      "* Makiko Tanaka                                      0.94615\n",
      "  makiko tanaka tanaka makiko born in nishiyama niigata january 14 1944 is a japanese politi\n",
      "  cian she is the daughter of former prime minister kakuei tanakatanaka\n",
      "\n",
      "* Theresa Arnold                                     0.94718\n",
      "  theresa arnold born september 20 1962 is a female boxer who beat a number of name fighters\n",
      "   during her career a native of boise idaho\n",
      "==========================================================\n",
      "Cluster 4     party:0.053 election:0.049 minister:0.041 elected:0.031 member:0.024 \n",
      "\n",
      "* Doug Lewis                                         0.95046\n",
      "  douglas grinslade doug lewis pc qc born april 17 1938 is a former canadian politician a ch\n",
      "  artered accountant and lawyer by training lewis entered the\n",
      "\n",
      "* Sidney Green (politician)                          0.95251\n",
      "  sidney green born august 1 1929 is a politician in manitoba canada he twice ran for the le\n",
      "  adership of the new democratic party of manitoba\n",
      "\n",
      "* Don Bell                                           0.95262\n",
      "  donald h bell born march 10 1942 in new westminster british columbia is a canadian politic\n",
      "  ian he is currently serving as a councillor for the\n",
      "\n",
      "* Blair Wilson                                       0.95396\n",
      "  blair wilson born may 18 1963 in north vancouver british columbia was the canadian member \n",
      "  of parliament mp in the 39th canadian parliament for west\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Judy Spence                                        0.95517\n",
      "  judith caroline spence born 19 may 1957 is an australian politician and former member of t\n",
      "  he legislative assembly of queensland for the australian labor party\n",
      "\n",
      "* Ross Ainsworth                                     0.95533\n",
      "  ross andrew ainsworth born 25 september 1947 is an australian politician he was a national\n",
      "   party of western australia member of the western australian legislative\n",
      "\n",
      "* Joseph A. Day                                      0.95673\n",
      "  joseph a day born january 24 1945 is a canadian politician he has been a canadian senator \n",
      "  since october 4 2001day studied at college militaire\n",
      "\n",
      "* Bernard Th%C3%A9riault                             0.95741\n",
      "  bernard thriault born november 12 1955 is a political figure in the province of new brunsw\n",
      "  ick canada he became chief of staff to premier of\n",
      "==========================================================\n",
      "Cluster 5     film:0.107 theatre:0.045 films:0.036 festival:0.032 directed:0.031 \n",
      "\n",
      "* Paul Popplewell                                    0.93019\n",
      "  paul popplewell was born in 1977 he became a professional actor at 16 leaving college afte\n",
      "  r gaining the lead role of simon in the multi\n",
      "\n",
      "* Denis C%C3%B4t%C3%A9                               0.93528\n",
      "  denis ct born november 16 1973 in perthandover new brunswick canada is an independent film\n",
      "  maker and producer living in quebec of brayon origin his experimental\n",
      "\n",
      "* Cristhian Andrews                                  0.93622\n",
      "  cristhian andrews born may 28 1990 is an american film director screenwriter producer comp\n",
      "  oser orchestrator film editor saxophonist and humanitarian he specialises in dramatisation\n",
      "\n",
      "* Paddy Considine                                    0.93633\n",
      "  patrick george paddy considine born 5 september 1973 is an english actor film director scr\n",
      "  eenwriter and musician he has played a number of dark troubled\n",
      "\n",
      "* Tracie Laymon                                      0.93663\n",
      "  tracie laymon is a screenwriter producer and film director laymon was raised in houston te\n",
      "  xas and studied film at the university of texas at austin\n",
      "\n",
      "* Mak 'Kusare                                        0.93799\n",
      "  mak kusare is a nigerian film director who won three awards for his first feature length f\n",
      "  ilm ninety degrees in 2006 at the zuma film\n",
      "\n",
      "* Yan Yan Mak                                        0.93975\n",
      "  yan yan mak is a hong kong based female awardwinning director she was born in the 1970s an\n",
      "  d graduated from the hong kong academy for\n",
      "\n",
      "* Tala Hadid                                         0.94068\n",
      "  tala hadid born in london is trained as a painter hadid was born to a moroccan mother and \n",
      "  an iraqi father her paternal grandfather a\n",
      "==========================================================\n",
      "Cluster 6     league:0.056 season:0.050 football:0.043 played:0.039 coach:0.036 \n",
      "\n",
      "* Justin Knoedler                                    0.94037\n",
      "  justin joseph knoedler born july 17 1980 in springfield illinois is a former major league \n",
      "  baseball catcherknoedler was originally drafted by the st louis cardinals\n",
      "\n",
      "* Neil Grayson                                       0.94795\n",
      "  neil grayson born 1 november 1964 in york is an english footballer who last played as a st\n",
      "  riker for sutton towngraysons first club was local\n",
      "\n",
      "* Tim Ireland                                        0.94796\n",
      "  timothy neal christopher ireland is a former professional baseball player he played parts \n",
      "  of two seasons in major league baseball for the kansas city royals\n",
      "\n",
      "* Steve Springer                                     0.95038\n",
      "  steven michael springer born february 11 1961 is an american former professional baseball \n",
      "  player who appeared in major league baseball as a third baseman and\n",
      "\n",
      "* Sol Campbell                                       0.95170\n",
      "  sulzeer jeremiah sol campbell born 18 september 1974 is a former england international foo\n",
      "  tballer a central defender he had a 19year career playing in the\n",
      "\n",
      "* Lee Maddison                                       0.95482\n",
      "  lee robert maddison born 5 october 1972 is a former professional association footballer wh\n",
      "  o played in the football league scottish football league and the scottish\n",
      "\n",
      "* Brad Dodd                                          0.95521\n",
      "  brad dodd born 23 may 1977 is a former australian rules footballer in the australian footb\n",
      "  all league afldodd was originally rookie drafted by the fremantle\n",
      "\n",
      "* Graeme Dunstan (footballer)                        0.95582\n",
      "  graeme dunstan born 29 december 1952 is a former australian rules footballer who played wi\n",
      "  th collingwood in the victorian football league vfl and norwood in\n",
      "==========================================================\n",
      "Cluster 7     university:0.029 research:0.025 law:0.023 professor:0.022 president:0.020 \n",
      "\n",
      "* James A. Joseph                                    0.96302\n",
      "  james a joseph born 1935 is an american former diplomatjoseph is professor of the practice\n",
      "   of public policy studies at duke university and founder of\n",
      "\n",
      "* John P. White                                      0.96591\n",
      "  john patrick white born february 27 1937 is an american university professor and a former \n",
      "  government official who served in the clinton administration he was\n",
      "\n",
      "* James A. Paul                                      0.96910\n",
      "  james a paul born june 10 1941 is a writer and nonprofit executive who has worked througho\n",
      "  ut his career in the field of international relations\n",
      "\n",
      "* Pasco Bowman II                                    0.97053\n",
      "  pasco middleton bowman ii born 1933 is a senior federal judge on the united states court o\n",
      "  f appeals for the eighth circuit a former fulbright\n",
      "\n",
      "* Thomas J. Miller (diplomat)                        0.97077\n",
      "  thomas j miller born 1948 was an american diplomat and previous threetime us ambassador wh\n",
      "  o currently serves as presidentceo of international executive service corps iesc\n",
      "\n",
      "* T. Marshall Hahn                                   0.97132\n",
      "  thomas marshall hahn jr born december 2 1926 was president of virginia polytechnic institu\n",
      "  te and state university from 1962 to 1974 and director of georgia\n",
      "\n",
      "* Thomas W. Krise                                    0.97141\n",
      "  thomas w krise phd born 1961 is the 13th president of pacific lutheran university in tacom\n",
      "  a washington united states he was appointed june 1 2012\n",
      "\n",
      "* George W. Landau                                   0.97163\n",
      "  george walter landau born march 4 1920 is a diplomat and former united states ambassador t\n",
      "  o paraguay chile and venezuelalandau was born march 4 1920\n",
      "==========================================================\n",
      "Cluster 8     championships:0.044 world:0.033 tour:0.031 championship:0.031 won:0.029 \n",
      "\n",
      "* Petra Lammert                                      0.94426\n",
      "  petra lammert born 3 march 1984 in freudenstadt badenwrttemberg is a former german shot pu\n",
      "  tter and current bobsledder she was the 2009 european indoor champion\n",
      "\n",
      "* Bouchra Cha%C3%A2bi                                0.94910\n",
      "  bouchra chaabi born 22 september 1980 in bougargouh is a moroccan longdistance runner who \n",
      "  specializes in the 3000 metres steeplechaseshe made her olympic debut at\n",
      "\n",
      "* Jenny Kallur                                       0.94931\n",
      "  jenny margareta kallur swedish pronunciation n kalr born 16 february 1981 is a former swed\n",
      "  ish track and field athlete who competed in hurdling and sprinting\n",
      "\n",
      "* Asami Chiba                                        0.95281\n",
      "  asami chiba asami chiba ne tanno born 25 september 1985 is a japanese sprinter who special\n",
      "  ises in the 400 metres she is the japanese record\n",
      "\n",
      "* Patricia Djat%C3%A9-Taillard                       0.95289\n",
      "  patricia djattaillard born 3 january 1971 is a retired french middle distance runner who s\n",
      "  pecialized in the 800 and 1500 metresshe was born in paris\n",
      "\n",
      "* Gulustan Mahmood                                   0.95440\n",
      "  gulustan mahmood ieso born 1 august 1991 also known as kolestan mahmoud is an iraqi track \n",
      "  and field athlete who competes in sprinting events she\n",
      "\n",
      "* Dawit Wolde                                        0.95484\n",
      "  dawit wolde born 19 may 1991 is an ethiopian middle distance runner who specialises in the\n",
      "   1500 metres a medallist at the world youth championships\n",
      "\n",
      "* Gonzalo Fern%C3%A1ndez-Casta%C3%B1o                0.95562\n",
      "  gonzalo fernndezcastao born 13 october 1980 is a spanish professional golfer who plays on \n",
      "  the european tourfernndezcastao was born in madrid he turned professional in\n",
      "==========================================================\n",
      "Cluster 9     he:0.012 that:0.011 radio:0.010 show:0.010 news:0.009 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Jonathan Klein (CNN)                               0.98290\n",
      "  jonathan klein is an american media executive he is the former president of cnnus who was \n",
      "  responsible for management oversight of all programming editorial tone\n",
      "\n",
      "* David McGuffin                                     0.98390\n",
      "  david mcguffin is a broadcast journalist working with national public radio in washington \n",
      "  dc as an editor on its flagship morning edition program prior to\n",
      "\n",
      "* Ian Collins (radio presenter)                      0.98458\n",
      "  ian collins is a british radio and television presenter and journalist he was the presente\n",
      "  r of the late show 10pm mon thurs on national radio\n",
      "\n",
      "* Tom Gross                                          0.98478\n",
      "  tom gross is a britishborn journalist international affairs commentator and human rights c\n",
      "  ampaigner specializing in the middle east in 2014 former pentagon official michael rubin\n",
      "\n",
      "* Malachi O'Doherty                                  0.98531\n",
      "  malachi odoherty born co donegal ireland 1951 is a journalist author and broadcaster in no\n",
      "  rthern irelandhe is the producer and presenter of the audio blog\n",
      "\n",
      "* Laurie Patton                                      0.98542\n",
      "  laurie patton is an australian media it and events industry executive and currently the ce\n",
      "  o of the internet society of australia he is a former\n",
      "\n",
      "* Frederick Clarkson                                 0.98550\n",
      "  frederick clarkson is an american journalist and public speaker in the fields of politics \n",
      "  and religion he is the author of eternal hostility the struggle\n",
      "\n",
      "* Howard Stern                                       0.98561\n",
      "  howard allan stern born january 12 1954 is an american radio and television personality pr\n",
      "  oducer author actor and photographer he is best known for his\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "visualize_document_clusters(wiki, tf_idf, centroids[k], cluster_assignment[k], k, map_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer have the clear split between men and women. Cluters 0 and 2 appear to be still mixed, but others are quite consistent in content.\n",
    "* Cluster 0: artists, poets, writers\n",
    "* Cluster 1: composers, songwriters, singers, music producers\n",
    "* Cluster 2: singers, songwriters, members of bands\n",
    "* Cluster 3: female figures from various fields\n",
    "* Cluster 4: politicians\n",
    "* Cluster 5: film directors\n",
    "* Cluster 6: soccer (football) players, baseball players\n",
    "* Cluster 7: professors, researchers, scholars, lawyers, judges\n",
    "* Cluster 8: track and field athletes\n",
    "* Cluster 9: journalists, tv personalities, media executives\n",
    "\n",
    "Clusters are now more pure, but some are qualitatively \"bigger\" than others. For instance, the category of scholars is more general than the category of film directors. Increasing the number of clusters may split larger clusters. Another way to look at the size of cluster is to count the number of articles in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 461,  189,  483,  674,  465,  314,  754,  824,  321, 1289])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(cluster_assignment[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Which of the 10 clusters above contains the greatest number of articles?\n",
    "\n",
    "1. Cluster 0: artists, poets, writers\n",
    "2. Cluster 4: politicians\n",
    "3. Cluster 5: film directors\n",
    "4. Cluster 7: professors, researchers, scholars, lawyers, judges\n",
    "5. Cluster 9: journalists, tv personalities, media executives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Which of the 10 clusters contains the least number of articles?\n",
    "\n",
    "1. Cluster 1: composers, songwriters, singers, music producers\n",
    "2. Cluster 3: female figures from various fields\n",
    "3. Cluster 6: soccer (football) players, baseball players\n",
    "4. Cluster 7: professors, researchers, scholars, lawyers, judges\n",
    "5. Cluster 8: track and field athletes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be at least some connection between the topical consistency of a cluster and the number of its member data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the case for K=25. For the sake of brevity, we do not print the content of documents. It turns out that the top words with highest TF-IDF weights in each cluster are representative of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Cluster 0     novel:0.091 fiction:0.064 published:0.042 novels:0.039 stories:0.037 \n",
      "==========================================================\n",
      "Cluster 1     prison:0.044 sentenced:0.029 arrested:0.029 sentence:0.026 convicted:0.025 \n",
      "==========================================================\n",
      "Cluster 2     music:0.063 band:0.038 album:0.029 jazz:0.028 orchestra:0.027 \n",
      "==========================================================\n",
      "Cluster 3     party:0.094 election:0.079 manitoba:0.054 liberal:0.053 elected:0.043 \n",
      "==========================================================\n",
      "Cluster 4     minister:0.098 party:0.054 election:0.049 parliament:0.035 prime:0.032 \n",
      "==========================================================\n",
      "Cluster 5     championships:0.074 olympics:0.047 marathon:0.047 she:0.046 world:0.043 \n",
      "==========================================================\n",
      "Cluster 6     album:0.127 her:0.065 released:0.061 she:0.051 single:0.043 \n",
      "==========================================================\n",
      "Cluster 7     football:0.135 afl:0.105 australian:0.082 club:0.069 melbourne:0.060 \n",
      "==========================================================\n",
      "Cluster 8     theatre:0.076 series:0.038 comedy:0.036 television:0.031 opera:0.029 \n",
      "==========================================================\n",
      "Cluster 9     season:0.057 basketball:0.057 coach:0.055 hockey:0.042 played:0.038 \n",
      "==========================================================\n",
      "Cluster 10     radio:0.081 news:0.080 show:0.046 anchor:0.039 television:0.034 \n",
      "==========================================================\n",
      "Cluster 11     baseball:0.123 league:0.116 major:0.053 minor:0.050 runs:0.048 \n",
      "==========================================================\n",
      "Cluster 12     president:0.026 chief:0.023 served:0.021 air:0.020 officer:0.019 \n",
      "==========================================================\n",
      "Cluster 13     she:0.153 her:0.097 women:0.017 actress:0.014 womens:0.013 \n",
      "==========================================================\n",
      "Cluster 14     art:0.137 museum:0.065 gallery:0.062 artist:0.034 work:0.030 \n",
      "==========================================================\n",
      "Cluster 15     mayor:0.091 board:0.036 city:0.028 council:0.024 ottawa:0.023 \n",
      "==========================================================\n",
      "Cluster 16     law:0.123 court:0.079 judge:0.059 district:0.048 attorney:0.038 \n",
      "==========================================================\n",
      "Cluster 17     poetry:0.209 poems:0.088 poet:0.072 poets:0.045 literary:0.044 \n",
      "==========================================================\n",
      "Cluster 18     league:0.067 football:0.061 club:0.052 season:0.051 cup:0.048 \n",
      "==========================================================\n",
      "Cluster 19     republican:0.063 district:0.052 senate:0.047 state:0.041 democratic:0.041 \n",
      "==========================================================\n",
      "Cluster 20     tour:0.101 racing:0.086 pga:0.085 formula:0.068 golf:0.064 \n",
      "==========================================================\n",
      "Cluster 21     he:0.012 book:0.011 his:0.010 that:0.010 has:0.008 \n",
      "==========================================================\n",
      "Cluster 22     film:0.157 films:0.050 festival:0.044 directed:0.034 documentary:0.028 \n",
      "==========================================================\n",
      "Cluster 23     research:0.046 university:0.039 professor:0.037 science:0.029 phd:0.020 \n",
      "==========================================================\n",
      "Cluster 24     rugby:0.176 wales:0.061 england:0.047 against:0.046 coach:0.045 \n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "visualize_document_clusters(wiki, tf_idf, centroids[25], cluster_assignment[25], 25,\n",
    "                            map_index_to_word, display_content=False) # turn off text for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looking at the representative examples and top words, we classify each cluster as follows. Notice the bolded items, which indicate the appearance of a new theme.\n",
    "* Cluster 0: **novelists**\n",
    "* Cluster 1: **criminals**\n",
    "* Cluster 2: composers, songwriters, singers, music producers\n",
    "* Cluster 3: politicians\n",
    "* Cluster 4: politicians\n",
    "* Cluster 5: track and field athletes\n",
    "* Cluster 6: female singers\n",
    "* Cluster 7: **Australian football players**\n",
    "* Cluster 8: **theatre, tv personalities, opera**\n",
    "* Cluster 9: basketballs, hockey players\n",
    "* Cluster 10: news anchors, radio hosts\n",
    "* Cluster 11: baseball\n",
    "* Cluster 12: **generals of U.S. Air Force**\n",
    "* Cluster 13: females figures of various fields\n",
    "* Cluster 14: painters, sculptors, artists\n",
    "* Cluster 15: **small govenrment officials**\n",
    "* Cluster 16: lawyers, judges, legal scholars\n",
    "* Cluster 17: **poets**\n",
    "* Cluster 18: soccer (football) players\n",
    "* Cluster 19: American politicians\n",
    "* Cluster 20: **golfers**\n",
    "* Cluster 21: (mixed; no clear theme)\n",
    "* Cluster 22: film directors \n",
    "* Cluster 23: professors, researchers, scholars\n",
    "* Cluster 24: rugby players\n",
    "\n",
    "Indeed, increasing K achieved the desired effect of breaking up large clusters.  Depending on the application, this may or may not be preferable to the K=10 analysis.\n",
    "\n",
    "Let's take it to the extreme and set K=100. We have a suspicion that this value is too large. Let us look at the top words from each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Cluster 0     marathon:0.142 championships:0.101 metres:0.094 she:0.085 athletics:0.068 \n",
      "==========================================================\n",
      "Cluster 1     pakistan:0.155 sindh:0.048 khan:0.040 pakistani:0.033 minister:0.031 \n",
      "==========================================================\n",
      "Cluster 2     organ:0.059 roach:0.051 blue:0.046 jazz:0.045 album:0.041 \n",
      "==========================================================\n",
      "Cluster 3     social:0.035 rabbi:0.029 university:0.029 education:0.026 history:0.023 \n",
      "==========================================================\n",
      "Cluster 4     law:0.153 legal:0.045 health:0.038 professor:0.033 university:0.026 \n",
      "==========================================================\n",
      "Cluster 5     karcher:0.058 emmy:0.057 ucla:0.056 dexter:0.045 goldstein:0.044 \n",
      "==========================================================\n",
      "Cluster 6     baseball:0.133 league:0.118 major:0.054 minor:0.053 games:0.043 \n",
      "==========================================================\n",
      "Cluster 7     band:0.073 drummer:0.047 rock:0.040 song:0.030 album:0.026 \n",
      "==========================================================\n",
      "Cluster 8     basketball:0.192 nba:0.094 points:0.064 season:0.050 team:0.043 \n",
      "==========================================================\n",
      "Cluster 9     church:0.090 pastor:0.078 brady:0.046 baptist:0.028 corke:0.027 \n",
      "==========================================================\n",
      "Cluster 10     rugby:0.177 wales:0.063 against:0.051 cup:0.048 played:0.046 \n",
      "==========================================================\n",
      "Cluster 11     philosophy:0.187 musgrave:0.089 macey:0.049 zealands:0.043 sterelny:0.043 \n",
      "==========================================================\n",
      "Cluster 12     balloon:0.126 wushu:0.059 lpez:0.057 xray:0.056 estrada:0.048 \n",
      "==========================================================\n",
      "Cluster 13     czarnik:0.079 bitch:0.075 rap:0.068 cuban:0.065 twinka:0.061 \n",
      "==========================================================\n",
      "Cluster 14     ireland:0.060 irish:0.051 i:0.046 northern:0.032 belfast:0.027 \n",
      "==========================================================\n",
      "Cluster 15     km:0.075 ray:0.057 newfoundland:0.034 esperanto:0.029 sea:0.024 \n",
      "==========================================================\n",
      "Cluster 16     band:0.056 arkansas:0.052 sun:0.039 burgess:0.037 bass:0.031 \n",
      "==========================================================\n",
      "Cluster 17     video:0.048 film:0.043 photography:0.042 directed:0.032 videos:0.031 \n",
      "==========================================================\n",
      "Cluster 18     film:0.217 festival:0.070 films:0.053 actor:0.038 best:0.034 \n",
      "==========================================================\n",
      "Cluster 19     band:0.065 lach:0.061 strokes:0.050 enz:0.043 sinn:0.042 \n",
      "==========================================================\n",
      "Cluster 20     jazz:0.234 music:0.054 band:0.045 trio:0.028 musicians:0.026 \n",
      "==========================================================\n",
      "Cluster 21     research:0.060 chemistry:0.053 science:0.045 university:0.038 professor:0.033 \n",
      "==========================================================\n",
      "Cluster 22     album:0.109 released:0.065 music:0.046 dj:0.041 records:0.035 \n",
      "==========================================================\n",
      "Cluster 23     opera:0.281 she:0.060 operatic:0.048 her:0.045 role:0.041 \n",
      "==========================================================\n",
      "Cluster 24     jersey:0.048 democratic:0.045 county:0.040 airport:0.035 new:0.029 \n",
      "==========================================================\n",
      "Cluster 25     racing:0.129 formula:0.090 race:0.071 driver:0.066 car:0.063 \n",
      "==========================================================\n",
      "Cluster 26     film:0.066 films:0.031 music:0.030 starring:0.028 television:0.025 \n",
      "==========================================================\n",
      "Cluster 27     show:0.034 jimmy:0.032 sullivan:0.032 briggs:0.028 films:0.028 \n",
      "==========================================================\n",
      "Cluster 28     tour:0.256 pga:0.229 golf:0.163 open:0.070 golfer:0.066 \n",
      "==========================================================\n",
      "Cluster 29     violence:0.042 she:0.037 her:0.031 children:0.029 books:0.029 \n",
      "==========================================================\n",
      "Cluster 30     news:0.067 television:0.047 anchor:0.035 producer:0.035 show:0.030 \n",
      "==========================================================\n",
      "Cluster 31     air:0.253 force:0.147 pilot:0.066 commander:0.061 command:0.060 \n",
      "==========================================================\n",
      "Cluster 32     puerto:0.098 rico:0.079 governor:0.069 rivera:0.051 democratic:0.033 \n",
      "==========================================================\n",
      "Cluster 33     argentine:0.090 argentina:0.063 boca:0.050 team:0.047 juniors:0.043 \n",
      "==========================================================\n",
      "Cluster 34     engineering:0.066 computer:0.052 technology:0.043 systems:0.041 electrical:0.039 \n",
      "==========================================================\n",
      "Cluster 35     cricket:0.165 firstclass:0.133 match:0.079 matches:0.075 batsman:0.058 \n",
      "==========================================================\n",
      "Cluster 36     church:0.147 lds:0.081 bishop:0.072 churchs:0.043 theological:0.042 \n",
      "==========================================================\n",
      "Cluster 37     physics:0.043 energy:0.039 research:0.037 sri:0.030 cells:0.028 \n",
      "==========================================================\n",
      "Cluster 38     coach:0.090 soccer:0.084 football:0.049 ncaa:0.045 basketball:0.045 \n",
      "==========================================================\n",
      "Cluster 39     rs:0.066 stock:0.063 bergesen:0.062 conlon:0.060 happel:0.056 \n",
      "==========================================================\n",
      "Cluster 40     jean:0.091 de:0.088 le:0.062 ceyrac:0.058 et:0.056 \n",
      "==========================================================\n",
      "Cluster 41     olympics:0.066 championships:0.060 world:0.047 freestyle:0.046 summer:0.042 \n",
      "==========================================================\n",
      "Cluster 42     political:0.053 media:0.035 security:0.033 science:0.029 university:0.027 \n",
      "==========================================================\n",
      "Cluster 43     surf:0.119 roper:0.119 sanders:0.109 yater:0.106 griffin:0.095 \n",
      "==========================================================\n",
      "Cluster 44     football:0.134 afl:0.069 season:0.059 played:0.055 australian:0.054 \n",
      "==========================================================\n",
      "Cluster 45     fight:0.106 boxing:0.082 decision:0.058 title:0.056 round:0.056 \n",
      "==========================================================\n",
      "Cluster 46     mathematics:0.095 mathematical:0.071 theory:0.052 she:0.043 professor:0.042 \n",
      "==========================================================\n",
      "Cluster 47     art:0.149 gallery:0.075 museum:0.072 artist:0.035 exhibition:0.033 \n",
      "==========================================================\n",
      "Cluster 48     kabuki:0.250 kimono:0.169 torregrosa:0.136 mikami:0.117 shiina:0.117 \n",
      "==========================================================\n",
      "Cluster 49     literary:0.053 poetry:0.048 literature:0.036 poet:0.032 translation:0.029 \n",
      "==========================================================\n",
      "Cluster 50     glass:0.092 architecture:0.091 sculpture:0.056 architectural:0.055 she:0.038 \n",
      "==========================================================\n",
      "Cluster 51     design:0.121 designer:0.043 architecture:0.034 finnish:0.033 art:0.032 \n",
      "==========================================================\n",
      "Cluster 52     party:0.071 parliament:0.065 member:0.048 committee:0.043 european:0.037 \n",
      "==========================================================\n",
      "Cluster 53     greek:0.118 greece:0.039 athens:0.032 hellenic:0.029 capital:0.026 \n",
      "==========================================================\n",
      "Cluster 54     tennis:0.119 open:0.098 doubles:0.085 singles:0.057 she:0.048 \n",
      "==========================================================\n",
      "Cluster 55     miss:0.042 series:0.042 television:0.030 she:0.029 role:0.027 \n",
      "==========================================================\n",
      "Cluster 56     comedy:0.115 standup:0.056 haar:0.054 olm:0.054 comedian:0.050 \n",
      "==========================================================\n",
      "Cluster 57     dance:0.061 music:0.054 guitar:0.042 ballet:0.035 band:0.026 \n",
      "==========================================================\n",
      "Cluster 58     piano:0.076 jazz:0.055 bass:0.053 dudu:0.043 van:0.039 \n",
      "==========================================================\n",
      "Cluster 59     she:0.113 her:0.097 indonesian:0.041 indonesia:0.034 paus:0.032 \n",
      "==========================================================\n",
      "Cluster 60     she:0.154 her:0.108 actress:0.022 film:0.019 album:0.015 \n",
      "==========================================================\n",
      "Cluster 61     kong:0.130 hong:0.128 pottery:0.028 gardens:0.026 chinese:0.026 \n",
      "==========================================================\n",
      "Cluster 62     republican:0.071 district:0.060 house:0.049 senate:0.048 state:0.041 \n",
      "==========================================================\n",
      "Cluster 63     she:0.093 her:0.050 book:0.035 istanbul:0.031 turkish:0.031 \n",
      "==========================================================\n",
      "Cluster 64     cambridge:0.051 lawrence:0.047 biography:0.043 oxford:0.040 h:0.029 \n",
      "==========================================================\n",
      "Cluster 65     tokyo:0.076 ldp:0.074 minister:0.064 hayashi:0.060 party:0.059 \n",
      "==========================================================\n",
      "Cluster 66     theatre:0.186 broadway:0.065 musical:0.054 production:0.038 drama:0.034 \n",
      "==========================================================\n",
      "Cluster 67     minister:0.075 election:0.062 party:0.054 candidate:0.029 elected:0.027 \n",
      "==========================================================\n",
      "Cluster 68     music:0.130 orchestra:0.111 conductor:0.073 symphony:0.063 chamber:0.039 \n",
      "==========================================================\n",
      "Cluster 69     prison:0.045 sentenced:0.034 convicted:0.031 arrested:0.030 police:0.030 \n",
      "==========================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 70     wrestling:0.289 wrestler:0.116 heavyweight:0.069 wwe:0.054 grecoroman:0.046 \n",
      "==========================================================\n",
      "Cluster 71     texas:0.060 novel:0.047 austin:0.038 novels:0.021 comics:0.021 \n",
      "==========================================================\n",
      "Cluster 72     runs:0.115 league:0.104 baseball:0.091 batting:0.064 home:0.062 \n",
      "==========================================================\n",
      "Cluster 73     marketing:0.058 klein:0.056 communications:0.052 hello:0.045 kang:0.043 \n",
      "==========================================================\n",
      "Cluster 74     foreign:0.035 deputy:0.031 chief:0.030 ambassador:0.028 naval:0.026 \n",
      "==========================================================\n",
      "Cluster 75     ward:0.154 speed:0.038 muhammad:0.036 lieberman:0.031 mulholland:0.030 \n",
      "==========================================================\n",
      "Cluster 76     league:0.076 season:0.067 football:0.049 town:0.046 club:0.045 \n",
      "==========================================================\n",
      "Cluster 77     court:0.125 judge:0.098 law:0.079 district:0.074 attorney:0.055 \n",
      "==========================================================\n",
      "Cluster 78     anthropology:0.050 studies:0.047 islamic:0.034 folklore:0.033 university:0.032 \n",
      "==========================================================\n",
      "Cluster 79     band:0.058 album:0.055 songs:0.041 music:0.039 song:0.031 \n",
      "==========================================================\n",
      "Cluster 80     faber:0.073 worms:0.062 dada:0.059 hop:0.059 hip:0.056 \n",
      "==========================================================\n",
      "Cluster 81     poetry:0.230 poems:0.095 poet:0.071 review:0.052 literary:0.039 \n",
      "==========================================================\n",
      "Cluster 82     dublin:0.058 bishop:0.047 archbishop:0.047 catholic:0.043 pontifical:0.040 \n",
      "==========================================================\n",
      "Cluster 83     rights:0.053 gutirrez:0.030 independence:0.029 manitoba:0.027 human:0.026 \n",
      "==========================================================\n",
      "Cluster 84     novel:0.050 fiction:0.047 stories:0.041 published:0.037 book:0.034 \n",
      "==========================================================\n",
      "Cluster 85     liberal:0.124 australian:0.076 party:0.063 wine:0.053 election:0.050 \n",
      "==========================================================\n",
      "Cluster 86     radio:0.105 show:0.070 station:0.039 host:0.039 fm:0.037 \n",
      "==========================================================\n",
      "Cluster 87     pba:0.163 gujarat:0.142 modi:0.056 season:0.050 matches:0.049 \n",
      "==========================================================\n",
      "Cluster 88     hockey:0.199 nhl:0.142 season:0.083 ice:0.072 games:0.052 \n",
      "==========================================================\n",
      "Cluster 89     rights:0.107 nigerian:0.099 human:0.092 nigeria:0.088 humanist:0.040 \n",
      "==========================================================\n",
      "Cluster 90     thompson:0.046 album:0.041 million:0.031 music:0.025 sold:0.024 \n",
      "==========================================================\n",
      "Cluster 91     cup:0.084 football:0.076 team:0.056 uefa:0.053 club:0.049 \n",
      "==========================================================\n",
      "Cluster 92     polish:0.152 poland:0.074 warsaw:0.049 jewish:0.032 cyprus:0.031 \n",
      "==========================================================\n",
      "Cluster 93     piano:0.121 orchestra:0.085 competition:0.081 symphony:0.065 music:0.059 \n",
      "==========================================================\n",
      "Cluster 94     psychology:0.124 research:0.057 psychological:0.051 cognitive:0.044 developmental:0.039 \n",
      "==========================================================\n",
      "Cluster 95     coach:0.222 head:0.092 football:0.056 defensive:0.044 coaching:0.043 \n",
      "==========================================================\n",
      "Cluster 96     bbc:0.111 radio:0.099 series:0.040 she:0.038 television:0.036 \n",
      "==========================================================\n",
      "Cluster 97     buddhist:0.220 tibetan:0.126 zen:0.095 heng:0.072 fei:0.064 \n",
      "==========================================================\n",
      "Cluster 98     chess:0.404 grandmaster:0.093 tournament:0.077 championship:0.075 fide:0.054 \n",
      "==========================================================\n",
      "Cluster 99     president:0.026 board:0.025 executive:0.023 chief:0.022 she:0.021 \n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "k=100\n",
    "visualize_document_clusters(wiki, tf_idf, centroids[k], cluster_assignment[k], k,\n",
    "                            map_index_to_word, display_content=False)\n",
    "# turn off text for brevity -- turn it on if you are curious ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class of soccer (football) players has been broken up into 5 clusters (clusters 38, 44, 76, 91 and 95), although some may like the benefit of having a separate category for Australian Football League. The class of baseball players have been also broken into two clusters (6 and 72).\n",
    "\n",
    "**A high value of K encourages pure clusters, but we cannot keep increasing K. For large enough K, related documents end up going to different clusters.**\n",
    "\n",
    "That said, the result for K=100 is not entirely bad. After all, it gives us separate clusters for such categories as Scotland, Brazil, LGBT, computer science and the Mormon Church. If we set K somewhere between 25 and 100, we should be able to avoid breaking up clusters while discovering new ones.\n",
    "\n",
    "Also, we should ask ourselves how much **granularity** we want in our clustering. If we wanted a rough sketch of Wikipedia, we don't want too detailed clusters. On the other hand, having many clusters can be valuable when we are zooming into a certain part of Wikipedia.\n",
    "\n",
    "**There is no golden rule for choosing K. It all depends on the particular application and domain we are in.**\n",
    "\n",
    "Another heuristic people use that does not rely on so much visualization, which can be hard in many applications (including here!) is as follows.  Track heterogeneity versus K and look for the \"elbow\" of the curve where the heterogeneity decrease rapidly before this value of K, but then only gradually for larger values of K.  This naturally trades off between trying to minimize heterogeneity, but reduce model complexity.  In the heterogeneity versus K plot made above, we did not yet really see a flattening out of the heterogeneity, which might indicate that indeed K=100 is \"reasonable\" and we only see real overfitting for larger values of K (which are even harder to visualize using the methods we attempted above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Quiz Question**. Another sign of too large K is having lots of small clusters. Look at the distribution of cluster sizes (by number of member data points). How many of the 100 clusters have fewer than 44 articles, i.e. 0.004% of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.bincount(cluster_assignment[100])<=44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind though that tiny clusters aren't necessarily bad. A tiny cluster of documents that really look like each others is definitely preferable to a medium-sized cluster of documents with mixed content. However, having too few articles in a cluster may cause overfitting by reading too much into limited pool of training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
